{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6080a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "# from pylab import *\n",
    "# import keyword\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81c7476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nyt_10yrs.csv')\n",
    "# data = pd.read_csv('nyt_10yrs_original.csv')\n",
    "\n",
    "# Create a Datetime index\n",
    "import datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "# df['week'] = df['date'].dt.week\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "df = df[df.year != '2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055714c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>word_count</th>\n",
       "      <th>subsection_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>section_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Prosecutor Stands Out by Pushing Back</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>New York’s attorney general, Eric T. Schneider...</td>\n",
       "      <td>New York’s attorney general, Eric T. Schneider...</td>\n",
       "      <td>THE other day, in his office down on Wall Stre...</td>\n",
       "      <td>MB</td>\n",
       "      <td>1</td>\n",
       "      <td>Metro</td>\n",
       "      <td>1448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Alan Feuer', 'person': [{'fir...</td>\n",
       "      <td>['Attorneys General', 'Politics and Government...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying to Reverse a Guilty Plea, Blaming A.D.D.</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...</td>\n",
       "      <td>Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...</td>\n",
       "      <td>They met in 1986, the setting improbable for r...</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>Metro</td>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Michael Wilson', 'person': [{...</td>\n",
       "      <td>['Crime and Criminals', 'Pain-Relieving Drugs'...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Want to Join Me for a Game? Anyone?</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>The Sportaneous app has won awards in New York...</td>\n",
       "      <td>The Sportaneous app has won awards in New York...</td>\n",
       "      <td>APP: Sportaneous</td>\n",
       "      <td>MB</td>\n",
       "      <td>3</td>\n",
       "      <td>Metro</td>\n",
       "      <td>602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Joshua Brustein', 'person': [...</td>\n",
       "      <td>['Mobile Applications', 'Athletics and Sports']</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          headline       date  \\\n",
       "0        Top Prosecutor Stands Out by Pushing Back 2011-10-01   \n",
       "1  Trying to Reverse a Guilty Plea, Blaming A.D.D. 2011-10-01   \n",
       "2              Want to Join Me for a Game? Anyone? 2011-10-01   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  New York’s attorney general, Eric T. Schneider...   \n",
       "1  Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...   \n",
       "2  The Sportaneous app has won awards in New York...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  New York’s attorney general, Eric T. Schneider...   \n",
       "1  Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...   \n",
       "2  The Sportaneous app has won awards in New York...   \n",
       "\n",
       "                                      lead_paragraph print_section print_page  \\\n",
       "0  THE other day, in his office down on Wall Stre...            MB          1   \n",
       "1  They met in 1986, the setting improbable for r...             A         16   \n",
       "2                                   APP: Sportaneous            MB          3   \n",
       "\n",
       "  news_desk  word_count subsection_name document_type type_of_material  \\\n",
       "0     Metro        1448             NaN       article             News   \n",
       "1     Metro         891             NaN       article             News   \n",
       "2     Metro         602             NaN       article             News   \n",
       "\n",
       "  section_name                                             byline  \\\n",
       "0     New York  {'original': 'By Alan Feuer', 'person': [{'fir...   \n",
       "1     New York  {'original': 'By Michael Wilson', 'person': [{...   \n",
       "2     New York  {'original': 'By Joshua Brustein', 'person': [...   \n",
       "\n",
       "                                            keywords  year  month  day  \n",
       "0  ['Attorneys General', 'Politics and Government...  2011     10    1  \n",
       "1  ['Crime and Criminals', 'Pain-Relieving Drugs'...  2011     10    1  \n",
       "2    ['Mobile Applications', 'Athletics and Sports']  2011     10    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0474212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89616711",
   "metadata": {},
   "source": [
    "### CountVectorizer and TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e29b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6611ebab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (8902, 11836), indices imply (8912, 11836)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-61bed7aea9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheadline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m counts = pd.DataFrame(matrix.toarray(),\n\u001b[0m\u001b[1;32m      6\u001b[0m                   \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                   columns=cvec.get_feature_names())\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 )\n\u001b[1;32m    671\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    673\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (8902, 11836), indices imply (8912, 11836)"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "matrix = cvec.fit_transform(df.headline[10:])\n",
    "counts = pd.DataFrame(matrix.toarray(),\n",
    "                  index=df.section_name,\n",
    "                  columns=cvec.get_feature_names())\n",
    "\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d65cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = cvec.fit_transform([text])\n",
    "counts = pd.DataFrame(matrix.toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "# Show us the top 10 most common words\n",
    "counts.T.sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6753346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf87d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "#convert list to string and generate\n",
    "unique_string=(\" \").join(list(df['keywords']))\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate(unique_string)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"your_file_name\"+\".png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ea75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr2012 = df.groupby('year' == 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb80dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85fc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dc876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd53cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784d9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbf389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616eaf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29c3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "812d3019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hitomihoshino/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hitomihoshino/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hitomihoshino/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import bigrams,ngrams\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9167ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stopwords', 'wordnet.zip', 'stopwords.zip', 'gutenberg', 'wordnet', 'gutenberg.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c479932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['إذ',\n",
       " 'إذا',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'أف',\n",
       " 'أقل',\n",
       " 'أكثر',\n",
       " 'ألا',\n",
       " 'إلا',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللاتي',\n",
       " 'اللائي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أما',\n",
       " 'إما',\n",
       " 'أن',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'أنا',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'أنى',\n",
       " 'أنى',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'أو',\n",
       " 'أولاء',\n",
       " 'أولئك',\n",
       " 'أوه',\n",
       " 'آي',\n",
       " 'أي',\n",
       " 'أيها',\n",
       " 'إي',\n",
       " 'أين',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'إيه',\n",
       " 'بخ',\n",
       " 'بس',\n",
       " 'بعد',\n",
       " 'بعض',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بين',\n",
       " 'بيد',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'ثم',\n",
       " 'ثمة',\n",
       " 'حاشا',\n",
       " 'حبذا',\n",
       " 'حتى',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'خلا',\n",
       " 'دون',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ريث',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'شتان',\n",
       " 'عدا',\n",
       " 'عسى',\n",
       " 'عل',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'غير',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فلا',\n",
       " 'فمن',\n",
       " 'في',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'قد',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كم',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'لا',\n",
       " 'لاسيما',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'لئن',\n",
       " 'ليت',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'ما',\n",
       " 'ماذا',\n",
       " 'متى',\n",
       " 'مذ',\n",
       " 'مع',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'منذ',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'ها',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاهنا',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هؤلاء',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهو',\n",
       " 'يا',\n",
       " 'a',\n",
       " 'ad',\n",
       " 'altı',\n",
       " 'altmış',\n",
       " 'amma',\n",
       " 'arasında',\n",
       " 'artıq',\n",
       " 'ay',\n",
       " 'az',\n",
       " 'bax',\n",
       " 'belə',\n",
       " 'bəli',\n",
       " 'bəlkə',\n",
       " 'beş',\n",
       " 'bəy',\n",
       " 'bəzən',\n",
       " 'bəzi',\n",
       " 'bilər',\n",
       " 'bir',\n",
       " 'biraz',\n",
       " 'biri',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bizim',\n",
       " 'bizlər',\n",
       " 'bu',\n",
       " 'buna',\n",
       " 'bundan',\n",
       " 'bunların',\n",
       " 'bunu',\n",
       " 'bunun',\n",
       " 'buradan',\n",
       " 'bütün',\n",
       " 'ci',\n",
       " 'cı',\n",
       " 'çox',\n",
       " 'cu',\n",
       " 'cü',\n",
       " 'çünki',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'də',\n",
       " 'dedi',\n",
       " 'dək',\n",
       " 'dən',\n",
       " 'dəqiqə',\n",
       " 'deyil',\n",
       " 'dir',\n",
       " 'doqquz',\n",
       " 'doqsan',\n",
       " 'dörd',\n",
       " 'düz',\n",
       " 'ə',\n",
       " 'edən',\n",
       " 'edir',\n",
       " 'əgər',\n",
       " 'əlbəttə',\n",
       " 'elə',\n",
       " 'əlli',\n",
       " 'ən',\n",
       " 'əslində',\n",
       " 'et',\n",
       " 'etdi',\n",
       " 'etmə',\n",
       " 'etmək',\n",
       " 'faiz',\n",
       " 'gilə',\n",
       " 'görə',\n",
       " 'ha',\n",
       " 'haqqında',\n",
       " 'harada',\n",
       " 'hə',\n",
       " 'heç',\n",
       " 'həm',\n",
       " 'həmin',\n",
       " 'həmişə',\n",
       " 'hər',\n",
       " 'ı',\n",
       " 'idi',\n",
       " 'iki',\n",
       " 'il',\n",
       " 'ildə',\n",
       " 'ilə',\n",
       " 'ilk',\n",
       " 'in',\n",
       " 'indi',\n",
       " 'isə',\n",
       " 'istifadə',\n",
       " 'iyirmi',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'kimə',\n",
       " 'kimi',\n",
       " 'lakin',\n",
       " 'lap',\n",
       " 'məhz',\n",
       " 'mən',\n",
       " 'mənə',\n",
       " 'mirşey',\n",
       " 'nə',\n",
       " 'nəhayət',\n",
       " 'niyə',\n",
       " 'o',\n",
       " 'obirisi',\n",
       " 'of',\n",
       " 'olan',\n",
       " 'olar',\n",
       " 'olaraq',\n",
       " 'oldu',\n",
       " 'olduğu',\n",
       " 'olmadı',\n",
       " 'olmaz',\n",
       " 'olmuşdur',\n",
       " 'olsun',\n",
       " 'olur',\n",
       " 'on',\n",
       " 'ona',\n",
       " 'ondan',\n",
       " 'onlar',\n",
       " 'onlardan',\n",
       " 'onların ',\n",
       " 'onsuzda',\n",
       " 'onu',\n",
       " 'onun',\n",
       " 'oradan',\n",
       " 'otuz',\n",
       " 'öz',\n",
       " 'özü',\n",
       " 'qarşı',\n",
       " 'qədər',\n",
       " 'qırx',\n",
       " 'saat',\n",
       " 'sadəcə',\n",
       " 'saniyə',\n",
       " 'səhv',\n",
       " 'səkkiz',\n",
       " 'səksən',\n",
       " 'sən',\n",
       " 'sənə',\n",
       " 'sənin',\n",
       " 'siz',\n",
       " 'sizin',\n",
       " 'sizlər',\n",
       " 'sonra',\n",
       " 'təəssüf',\n",
       " 'ü',\n",
       " 'üç',\n",
       " 'üçün',\n",
       " 'var',\n",
       " 'və',\n",
       " 'xan',\n",
       " 'xanım',\n",
       " 'xeyr',\n",
       " 'ya',\n",
       " 'yalnız',\n",
       " 'yaxşı',\n",
       " 'yeddi',\n",
       " 'yenə',\n",
       " 'yəni',\n",
       " 'yetmiş',\n",
       " 'yox',\n",
       " 'yoxdur',\n",
       " 'yoxsa',\n",
       " 'yüz',\n",
       " 'zamanog',\n",
       " 'i',\n",
       " 'jeg',\n",
       " 'det',\n",
       " 'at',\n",
       " 'en',\n",
       " 'den',\n",
       " 'til',\n",
       " 'er',\n",
       " 'som',\n",
       " 'på',\n",
       " 'de',\n",
       " 'med',\n",
       " 'han',\n",
       " 'af',\n",
       " 'for',\n",
       " 'ikke',\n",
       " 'der',\n",
       " 'var',\n",
       " 'mig',\n",
       " 'sig',\n",
       " 'men',\n",
       " 'et',\n",
       " 'har',\n",
       " 'om',\n",
       " 'vi',\n",
       " 'min',\n",
       " 'havde',\n",
       " 'ham',\n",
       " 'hun',\n",
       " 'nu',\n",
       " 'over',\n",
       " 'da',\n",
       " 'fra',\n",
       " 'du',\n",
       " 'ud',\n",
       " 'sin',\n",
       " 'dem',\n",
       " 'os',\n",
       " 'op',\n",
       " 'man',\n",
       " 'hans',\n",
       " 'hvor',\n",
       " 'eller',\n",
       " 'hvad',\n",
       " 'skal',\n",
       " 'selv',\n",
       " 'her',\n",
       " 'alle',\n",
       " 'vil',\n",
       " 'blev',\n",
       " 'kunne',\n",
       " 'ind',\n",
       " 'når',\n",
       " 'være',\n",
       " 'dog',\n",
       " 'noget',\n",
       " 'ville',\n",
       " 'jo',\n",
       " 'deres',\n",
       " 'efter',\n",
       " 'ned',\n",
       " 'skulle',\n",
       " 'denne',\n",
       " 'end',\n",
       " 'dette',\n",
       " 'mit',\n",
       " 'også',\n",
       " 'under',\n",
       " 'have',\n",
       " 'dig',\n",
       " 'anden',\n",
       " 'hende',\n",
       " 'mine',\n",
       " 'alt',\n",
       " 'meget',\n",
       " 'sit',\n",
       " 'sine',\n",
       " 'vor',\n",
       " 'mod',\n",
       " 'disse',\n",
       " 'hvis',\n",
       " 'din',\n",
       " 'nogle',\n",
       " 'hos',\n",
       " 'blive',\n",
       " 'mange',\n",
       " 'ad',\n",
       " 'bliver',\n",
       " 'hendes',\n",
       " 'været',\n",
       " 'thi',\n",
       " 'jer',\n",
       " 'sådan',\n",
       " 'de',\n",
       " 'en',\n",
       " 'van',\n",
       " 'ik',\n",
       " 'te',\n",
       " 'dat',\n",
       " 'die',\n",
       " 'in',\n",
       " 'een',\n",
       " 'hij',\n",
       " 'het',\n",
       " 'niet',\n",
       " 'zijn',\n",
       " 'is',\n",
       " 'was',\n",
       " 'op',\n",
       " 'aan',\n",
       " 'met',\n",
       " 'als',\n",
       " 'voor',\n",
       " 'had',\n",
       " 'er',\n",
       " 'maar',\n",
       " 'om',\n",
       " 'hem',\n",
       " 'dan',\n",
       " 'zou',\n",
       " 'of',\n",
       " 'wat',\n",
       " 'mijn',\n",
       " 'men',\n",
       " 'dit',\n",
       " 'zo',\n",
       " 'door',\n",
       " 'over',\n",
       " 'ze',\n",
       " 'zich',\n",
       " 'bij',\n",
       " 'ook',\n",
       " 'tot',\n",
       " 'je',\n",
       " 'mij',\n",
       " 'uit',\n",
       " 'der',\n",
       " 'daar',\n",
       " 'haar',\n",
       " 'naar',\n",
       " 'heb',\n",
       " 'hoe',\n",
       " 'heeft',\n",
       " 'hebben',\n",
       " 'deze',\n",
       " 'u',\n",
       " 'want',\n",
       " 'nog',\n",
       " 'zal',\n",
       " 'me',\n",
       " 'zij',\n",
       " 'nu',\n",
       " 'ge',\n",
       " 'geen',\n",
       " 'omdat',\n",
       " 'iets',\n",
       " 'worden',\n",
       " 'toch',\n",
       " 'al',\n",
       " 'waren',\n",
       " 'veel',\n",
       " 'meer',\n",
       " 'doen',\n",
       " 'toen',\n",
       " 'moet',\n",
       " 'ben',\n",
       " 'zonder',\n",
       " 'kan',\n",
       " 'hun',\n",
       " 'dus',\n",
       " 'alles',\n",
       " 'onder',\n",
       " 'ja',\n",
       " 'eens',\n",
       " 'hier',\n",
       " 'wie',\n",
       " 'werd',\n",
       " 'altijd',\n",
       " 'doch',\n",
       " 'wordt',\n",
       " 'wezen',\n",
       " 'kunnen',\n",
       " 'ons',\n",
       " 'zelf',\n",
       " 'tegen',\n",
       " 'na',\n",
       " 'reeds',\n",
       " 'wil',\n",
       " 'kon',\n",
       " 'niets',\n",
       " 'uw',\n",
       " 'iemand',\n",
       " 'geweest',\n",
       " 'andere',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'olla',\n",
       " 'olen',\n",
       " 'olet',\n",
       " 'on',\n",
       " 'olemme',\n",
       " 'olette',\n",
       " 'ovat',\n",
       " 'ole',\n",
       " 'oli',\n",
       " 'olisi',\n",
       " 'olisit',\n",
       " 'olisin',\n",
       " 'olisimme',\n",
       " 'olisitte',\n",
       " 'olisivat',\n",
       " 'olit',\n",
       " 'olin',\n",
       " 'olimme',\n",
       " 'olitte',\n",
       " 'olivat',\n",
       " 'ollut',\n",
       " 'olleet',\n",
       " 'en',\n",
       " 'et',\n",
       " 'ei',\n",
       " 'emme',\n",
       " 'ette',\n",
       " 'eivät',\n",
       " 'minä',\n",
       " 'minun',\n",
       " 'minut',\n",
       " 'minua',\n",
       " 'minussa',\n",
       " 'minusta',\n",
       " 'minuun',\n",
       " 'minulla',\n",
       " 'minulta',\n",
       " 'minulle',\n",
       " 'sinä',\n",
       " 'sinun',\n",
       " 'sinut',\n",
       " 'sinua',\n",
       " 'sinussa',\n",
       " 'sinusta',\n",
       " 'sinuun',\n",
       " 'sinulla',\n",
       " 'sinulta',\n",
       " 'sinulle',\n",
       " 'hän',\n",
       " 'hänen',\n",
       " 'hänet',\n",
       " 'häntä',\n",
       " 'hänessä',\n",
       " 'hänestä',\n",
       " 'häneen',\n",
       " 'hänellä',\n",
       " 'häneltä',\n",
       " 'hänelle',\n",
       " 'me',\n",
       " 'meidän',\n",
       " 'meidät',\n",
       " 'meitä',\n",
       " 'meissä',\n",
       " 'meistä',\n",
       " 'meihin',\n",
       " 'meillä',\n",
       " 'meiltä',\n",
       " 'meille',\n",
       " 'te',\n",
       " 'teidän',\n",
       " 'teidät',\n",
       " 'teitä',\n",
       " 'teissä',\n",
       " 'teistä',\n",
       " 'teihin',\n",
       " 'teillä',\n",
       " 'teiltä',\n",
       " 'teille',\n",
       " 'he',\n",
       " 'heidän',\n",
       " 'heidät',\n",
       " 'heitä',\n",
       " 'heissä',\n",
       " 'heistä',\n",
       " 'heihin',\n",
       " 'heillä',\n",
       " 'heiltä',\n",
       " 'heille',\n",
       " 'tämä',\n",
       " 'tämän',\n",
       " 'tätä',\n",
       " 'tässä',\n",
       " 'tästä',\n",
       " 'tähän',\n",
       " 'tallä',\n",
       " 'tältä',\n",
       " 'tälle',\n",
       " 'tänä',\n",
       " 'täksi',\n",
       " 'tuo',\n",
       " 'tuon',\n",
       " 'tuotä',\n",
       " 'tuossa',\n",
       " 'tuosta',\n",
       " 'tuohon',\n",
       " 'tuolla',\n",
       " 'tuolta',\n",
       " 'tuolle',\n",
       " 'tuona',\n",
       " 'tuoksi',\n",
       " 'se',\n",
       " 'sen',\n",
       " 'sitä',\n",
       " 'siinä',\n",
       " 'siitä',\n",
       " 'siihen',\n",
       " 'sillä',\n",
       " 'siltä',\n",
       " 'sille',\n",
       " 'sinä',\n",
       " 'siksi',\n",
       " 'nämä',\n",
       " 'näiden',\n",
       " 'näitä',\n",
       " 'näissä',\n",
       " 'näistä',\n",
       " 'näihin',\n",
       " 'näillä',\n",
       " 'näiltä',\n",
       " 'näille',\n",
       " 'näinä',\n",
       " 'näiksi',\n",
       " 'nuo',\n",
       " 'noiden',\n",
       " 'noita',\n",
       " 'noissa',\n",
       " 'noista',\n",
       " 'noihin',\n",
       " 'noilla',\n",
       " 'noilta',\n",
       " 'noille',\n",
       " 'noina',\n",
       " 'noiksi',\n",
       " 'ne',\n",
       " 'niiden',\n",
       " 'niitä',\n",
       " 'niissä',\n",
       " 'niistä',\n",
       " 'niihin',\n",
       " 'niillä',\n",
       " 'niiltä',\n",
       " 'niille',\n",
       " 'niinä',\n",
       " 'niiksi',\n",
       " 'kuka',\n",
       " 'kenen',\n",
       " 'kenet',\n",
       " 'ketä',\n",
       " 'kenessä',\n",
       " 'kenestä',\n",
       " 'keneen',\n",
       " 'kenellä',\n",
       " 'keneltä',\n",
       " 'kenelle',\n",
       " 'kenenä',\n",
       " 'keneksi',\n",
       " 'ketkä',\n",
       " 'keiden',\n",
       " 'ketkä',\n",
       " 'keitä',\n",
       " 'keissä',\n",
       " 'keistä',\n",
       " 'keihin',\n",
       " 'keillä',\n",
       " 'keiltä',\n",
       " 'keille',\n",
       " 'keinä',\n",
       " 'keiksi',\n",
       " 'mikä',\n",
       " 'minkä',\n",
       " 'minkä',\n",
       " 'mitä',\n",
       " 'missä',\n",
       " 'mistä',\n",
       " 'mihin',\n",
       " 'millä',\n",
       " 'miltä',\n",
       " 'mille',\n",
       " 'minä',\n",
       " 'miksi',\n",
       " 'mitkä',\n",
       " 'joka',\n",
       " 'jonka',\n",
       " 'jota',\n",
       " 'jossa',\n",
       " 'josta',\n",
       " 'johon',\n",
       " 'jolla',\n",
       " 'jolta',\n",
       " 'jolle',\n",
       " 'jona',\n",
       " 'joksi',\n",
       " 'jotka',\n",
       " 'joiden',\n",
       " 'joita',\n",
       " 'joissa',\n",
       " 'joista',\n",
       " 'joihin',\n",
       " 'joilla',\n",
       " 'joilta',\n",
       " 'joille',\n",
       " 'joina',\n",
       " 'joiksi',\n",
       " 'että',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c18e692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/hitomihoshino/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df601b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>word_count</th>\n",
       "      <th>subsection_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>section_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Prosecutor Stands Out by Pushing Back</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>New York’s attorney general, Eric T. Schneider...</td>\n",
       "      <td>New York’s attorney general, Eric T. Schneider...</td>\n",
       "      <td>THE other day, in his office down on Wall Stre...</td>\n",
       "      <td>MB</td>\n",
       "      <td>1</td>\n",
       "      <td>Metro</td>\n",
       "      <td>1448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Alan Feuer', 'person': [{'fir...</td>\n",
       "      <td>['Attorneys General', 'Politics and Government...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying to Reverse a Guilty Plea, Blaming A.D.D.</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...</td>\n",
       "      <td>Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...</td>\n",
       "      <td>They met in 1986, the setting improbable for r...</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>Metro</td>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Michael Wilson', 'person': [{...</td>\n",
       "      <td>['Crime and Criminals', 'Pain-Relieving Drugs'...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Want to Join Me for a Game? Anyone?</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>The Sportaneous app has won awards in New York...</td>\n",
       "      <td>The Sportaneous app has won awards in New York...</td>\n",
       "      <td>APP: Sportaneous</td>\n",
       "      <td>MB</td>\n",
       "      <td>3</td>\n",
       "      <td>Metro</td>\n",
       "      <td>602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Joshua Brustein', 'person': [...</td>\n",
       "      <td>['Mobile Applications', 'Athletics and Sports']</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yankees-Tigers Game Suspended due to Rain</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Game 1 will pick up in the second inning, resu...</td>\n",
       "      <td>Game 1 will pick up in the second inning, resu...</td>\n",
       "      <td>With the weather radar showing storms litterin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1587</td>\n",
       "      <td>Baseball</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Sports</td>\n",
       "      <td>{'original': 'By Nick Corasaniti', 'person': [...</td>\n",
       "      <td>['Baseball']</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al-Awlaki Killed in Drone Strike</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Anwar Al-Awlaki was killed in an American dron...</td>\n",
       "      <td>Anwar Al-Awlaki was killed in an American dron...</td>\n",
       "      <td>Anwar Al-Awlaki was killed in an American dron...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>Slideshow</td>\n",
       "      <td>World</td>\n",
       "      <td>{'original': '', 'person': [], 'organization':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          headline       date  \\\n",
       "0        Top Prosecutor Stands Out by Pushing Back 2011-10-01   \n",
       "1  Trying to Reverse a Guilty Plea, Blaming A.D.D. 2011-10-01   \n",
       "2              Want to Join Me for a Game? Anyone? 2011-10-01   \n",
       "3        Yankees-Tigers Game Suspended due to Rain 2011-10-01   \n",
       "4                 Al-Awlaki Killed in Drone Strike 2011-10-01   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  New York’s attorney general, Eric T. Schneider...   \n",
       "1  Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...   \n",
       "2  The Sportaneous app has won awards in New York...   \n",
       "3  Game 1 will pick up in the second inning, resu...   \n",
       "4  Anwar Al-Awlaki was killed in an American dron...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  New York’s attorney general, Eric T. Schneider...   \n",
       "1  Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...   \n",
       "2  The Sportaneous app has won awards in New York...   \n",
       "3  Game 1 will pick up in the second inning, resu...   \n",
       "4  Anwar Al-Awlaki was killed in an American dron...   \n",
       "\n",
       "                                      lead_paragraph print_section print_page  \\\n",
       "0  THE other day, in his office down on Wall Stre...            MB          1   \n",
       "1  They met in 1986, the setting improbable for r...             A         16   \n",
       "2                                   APP: Sportaneous            MB          3   \n",
       "3  With the weather radar showing storms litterin...           NaN        NaN   \n",
       "4  Anwar Al-Awlaki was killed in an American dron...           NaN        NaN   \n",
       "\n",
       "  news_desk  word_count subsection_name document_type type_of_material  \\\n",
       "0     Metro        1448             NaN       article             News   \n",
       "1     Metro         891             NaN       article             News   \n",
       "2     Metro         602             NaN       article             News   \n",
       "3       NaN        1587        Baseball       article             News   \n",
       "4     World           0             NaN    multimedia        Slideshow   \n",
       "\n",
       "  section_name                                             byline  \\\n",
       "0     New York  {'original': 'By Alan Feuer', 'person': [{'fir...   \n",
       "1     New York  {'original': 'By Michael Wilson', 'person': [{...   \n",
       "2     New York  {'original': 'By Joshua Brustein', 'person': [...   \n",
       "3       Sports  {'original': 'By Nick Corasaniti', 'person': [...   \n",
       "4        World  {'original': '', 'person': [], 'organization':...   \n",
       "\n",
       "                                            keywords  year  month  day  \n",
       "0  ['Attorneys General', 'Politics and Government...  2011     10    1  \n",
       "1  ['Crime and Criminals', 'Pain-Relieving Drugs'...  2011     10    1  \n",
       "2    ['Mobile Applications', 'Athletics and Sports']  2011     10    1  \n",
       "3                                       ['Baseball']  2011     10    1  \n",
       "4                                                 []  2011     10    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a32374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in df['headline']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f8e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenizer(tweet):\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    tweet = re.sub('http[s]?://\\S+', '', tweet)\n",
    "\n",
    "    \n",
    "    # remove special characters, foreign languages and digits. Emojis are retained for now. \n",
    "    tweet = re.sub('[^a-zA-Z]',' ',tweet)\n",
    "\n",
    "\n",
    "   # Remove user @ references and '#' from tweet\n",
    "    tweet = re.sub(r'\\d|\\@\\w+|\\#','', tweet)\n",
    "    \n",
    "    # Use nltk TweetTokenizer to tokenize tweet text\n",
    "    ttknzr = TweetTokenizer(\n",
    "        preserve_case=False, reduce_len=True,strip_handles=True).tokenize(tweet)\n",
    "    filtered_words = [w for w in ttknzr if not w in stop_words]\n",
    "    \n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# function to convert text to n-grams\n",
    "def get_ngrams(text,n=2):\n",
    "    n_grams = ngrams(word_tokenize(text), n)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def get_word_pos(word):\n",
    "    \n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def get_lemma(sentence):\n",
    "    lemma = [lemmatizer.lemmatize(w, get_word_pos(w)) for w in nltk.word_tokenize(sentence)]\n",
    "    return \" \".join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4311ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tweet text\n",
    "df['tweet_token2'] = df['keywords'].apply(tweet_tokenizer)\n",
    "\n",
    "# Lemmatize the tweet token\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemma2'] = df['keywords'].apply(get_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d6c6eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>abstract</th>\n",
       "      <th>snippet</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>print_section</th>\n",
       "      <th>print_page</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>word_count</th>\n",
       "      <th>subsection_name</th>\n",
       "      <th>...</th>\n",
       "      <th>section_name</th>\n",
       "      <th>byline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tweet_token2</th>\n",
       "      <th>lemma2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Prosecutor Stands Out by Pushing Back</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>New York’s attorney general, Eric T. Schneider...</td>\n",
       "      <td>New York’s attorney general, Eric T. Schneider...</td>\n",
       "      <td>THE other day, in his office down on Wall Stre...</td>\n",
       "      <td>MB</td>\n",
       "      <td>1</td>\n",
       "      <td>Metro</td>\n",
       "      <td>1448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Alan Feuer', 'person': [{'fir...</td>\n",
       "      <td>['Attorneys General', 'Politics and Government...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>top prosecutor stands pushing back</td>\n",
       "      <td>Top Prosecutor Stands Out by Pushing Back</td>\n",
       "      <td>attorneys general politics government banking ...</td>\n",
       "      <td>[ 'Attorneys General ' , 'Politics and Governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trying to Reverse a Guilty Plea, Blaming A.D.D.</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...</td>\n",
       "      <td>Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...</td>\n",
       "      <td>They met in 1986, the setting improbable for r...</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>Metro</td>\n",
       "      <td>891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Michael Wilson', 'person': [{...</td>\n",
       "      <td>['Crime and Criminals', 'Pain-Relieving Drugs'...</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>trying reverse guilty plea blaming</td>\n",
       "      <td>Trying to Reverse a Guilty Plea , Blaming A.D.D .</td>\n",
       "      <td>crime criminals pain relieving drugs decisions...</td>\n",
       "      <td>[ 'Crime and Criminals ' , 'Pain-Relieving Dru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Want to Join Me for a Game? Anyone?</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>The Sportaneous app has won awards in New York...</td>\n",
       "      <td>The Sportaneous app has won awards in New York...</td>\n",
       "      <td>APP: Sportaneous</td>\n",
       "      <td>MB</td>\n",
       "      <td>3</td>\n",
       "      <td>Metro</td>\n",
       "      <td>602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td>{'original': 'By Joshua Brustein', 'person': [...</td>\n",
       "      <td>['Mobile Applications', 'Athletics and Sports']</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>want join game anyone</td>\n",
       "      <td>Want to Join Me for a Game ? Anyone ?</td>\n",
       "      <td>mobile applications athletics sports</td>\n",
       "      <td>[ 'Mobile Applications ' , 'Athletics and Spor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          headline       date  \\\n",
       "0        Top Prosecutor Stands Out by Pushing Back 2011-10-01   \n",
       "1  Trying to Reverse a Guilty Plea, Blaming A.D.D. 2011-10-01   \n",
       "2              Want to Join Me for a Game? Anyone? 2011-10-01   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  New York’s attorney general, Eric T. Schneider...   \n",
       "1  Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...   \n",
       "2  The Sportaneous app has won awards in New York...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  New York’s attorney general, Eric T. Schneider...   \n",
       "1  Dr. Jeffrey R. Burkes pleaded guilty in 2007 t...   \n",
       "2  The Sportaneous app has won awards in New York...   \n",
       "\n",
       "                                      lead_paragraph print_section print_page  \\\n",
       "0  THE other day, in his office down on Wall Stre...            MB          1   \n",
       "1  They met in 1986, the setting improbable for r...             A         16   \n",
       "2                                   APP: Sportaneous            MB          3   \n",
       "\n",
       "  news_desk  word_count subsection_name  ... section_name  \\\n",
       "0     Metro        1448             NaN  ...     New York   \n",
       "1     Metro         891             NaN  ...     New York   \n",
       "2     Metro         602             NaN  ...     New York   \n",
       "\n",
       "                                              byline  \\\n",
       "0  {'original': 'By Alan Feuer', 'person': [{'fir...   \n",
       "1  {'original': 'By Michael Wilson', 'person': [{...   \n",
       "2  {'original': 'By Joshua Brustein', 'person': [...   \n",
       "\n",
       "                                            keywords  year month  day  \\\n",
       "0  ['Attorneys General', 'Politics and Government...  2011    10    1   \n",
       "1  ['Crime and Criminals', 'Pain-Relieving Drugs'...  2011    10    1   \n",
       "2    ['Mobile Applications', 'Athletics and Sports']  2011    10    1   \n",
       "\n",
       "                          tweet_token  \\\n",
       "0  top prosecutor stands pushing back   \n",
       "1  trying reverse guilty plea blaming   \n",
       "2               want join game anyone   \n",
       "\n",
       "                                               lemma  \\\n",
       "0          Top Prosecutor Stands Out by Pushing Back   \n",
       "1  Trying to Reverse a Guilty Plea , Blaming A.D.D .   \n",
       "2              Want to Join Me for a Game ? Anyone ?   \n",
       "\n",
       "                                        tweet_token2  \\\n",
       "0  attorneys general politics government banking ...   \n",
       "1  crime criminals pain relieving drugs decisions...   \n",
       "2               mobile applications athletics sports   \n",
       "\n",
       "                                              lemma2  \n",
       "0  [ 'Attorneys General ' , 'Politics and Governm...  \n",
       "1  [ 'Crime and Criminals ' , 'Pain-Relieving Dru...  \n",
       "2  [ 'Mobile Applications ' , 'Athletics and Spor...  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a80e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b24996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc487e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18152fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d36ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
